{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#!pip install transformers -U"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:04:36.690027Z",
     "start_time": "2024-06-29T20:04:36.666072Z"
    }
   },
   "id": "445de116bad59ad1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import importlib\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:04:38.067143Z",
     "start_time": "2024-06-29T20:04:36.671666Z"
    }
   },
   "id": "ba8b47a55ac570c2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding path: /Users/johnschroter/IdeaProjects/Sigma-GPT/src\n"
     ]
    }
   ],
   "source": [
    "# Add the correct path to the local transformers directory\n",
    "local_path = os.path.abspath('../src/')\n",
    "print(\"Adding path:\", local_path)  # Verify the path to be added\n",
    "sys.path.insert(0, local_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:04:38.072104Z",
     "start_time": "2024-06-29T20:04:38.067296Z"
    }
   },
   "id": "9430a53d8e229b91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating local Path to files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3e000b06fe6e35b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Confirming local copies are being used"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a54ad731fc72df55"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/johnschroter/IdeaProjects/Sigma-GPT/src/transformers/models/gpt2/tokenization_gpt2.py\n",
      "/Users/johnschroter/IdeaProjects/Sigma-GPT/src/transformers/models/gpt2/modeling_gpt2.py\n"
     ]
    }
   ],
   "source": [
    "# Import your modified GPT2 classes\n",
    "from transformers.models.gpt2.tokenization_gpt2 import *\n",
    "from transformers.models.gpt2.modeling_gpt2 import *\n",
    "\n",
    "# Verify that the modules are being loaded from the correct path\n",
    "import transformers.models.gpt2.tokenization_gpt2\n",
    "import transformers.models.gpt2.modeling_gpt2\n",
    "\n",
    "print(transformers.models.gpt2.tokenization_gpt2.__file__)  # Should point to your local file\n",
    "print(transformers.models.gpt2.modeling_gpt2.__file__)  # Should point to your local file"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:04:38.366340Z",
     "start_time": "2024-06-29T20:04:38.071269Z"
    }
   },
   "id": "f4f96fca5e604776"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Randomly initilizing sigma-gpt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5b62687d261dc19"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Initialize the tokenizer (pre-trained vocab is fine for tokenizer)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# Initialize the configuration with random parameters\n",
    "config = GPT2Config()\n",
    "\n",
    "# Initialize the model with the custom configuration\n",
    "model = CustomGPT2LMHeadModel(config)\n",
    "\n",
    "# Initialize weights randomly\n",
    "model.init_weights()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:04:42.826446Z",
     "start_time": "2024-06-29T20:04:38.367223Z"
    }
   },
   "id": "f2b440488042861b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "load in dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d3381642b2613f7"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/4358 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6dae15bb0b52463687f0594a40c7da9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb63c44349f84564b2da5b04f0b6d8b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fcb365ade98245d5a1ee8e240396cc25"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Wikitext-2 dataset\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "\n",
    "# Preprocess the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "eval_dataset = tokenized_datasets[\"validation\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:04:59.368327Z",
     "start_time": "2024-06-29T20:04:42.828231Z"
    }
   },
   "id": "dfc23dfd7af026ba"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class AdaptiveShuffle:\n",
    "    def __init__(self, initial_shuffle_percentage=0.0, max_adjustment_per_epoch=0.05, performance_threshold=0.01):\n",
    "        self.shuffle_percentage = initial_shuffle_percentage\n",
    "        self.max_adjustment_per_epoch = max_adjustment_per_epoch\n",
    "        self.performance_threshold = performance_threshold\n",
    "        self.previous_loss = None\n",
    "\n",
    "    def adjust_shuffle_percentage(self, current_loss):\n",
    "        if self.previous_loss is not None:\n",
    "            improvement = (self.previous_loss - current_loss) / self.previous_loss\n",
    "            if improvement > self.performance_threshold:\n",
    "                self.shuffle_percentage = min(self.shuffle_percentage + self.max_adjustment_per_epoch, 1.0)\n",
    "            elif improvement < -self.performance_threshold:\n",
    "                self.shuffle_percentage = max(self.shuffle_percentage - self.max_adjustment_per_epoch, 0.0)\n",
    "        self.previous_loss = current_loss\n",
    "\n",
    "    def get_current_shuffle_percentage(self):\n",
    "        return self.shuffle_percentage\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:04:59.374645Z",
     "start_time": "2024-06-29T20:04:59.370585Z"
    }
   },
   "id": "258c15df673fba75"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ShuffledDataset(Dataset):\n",
    "    def __init__(self, input_ids, position_ids, next_position_ids, attention_mask):\n",
    "        self.input_ids = input_ids\n",
    "        self.position_ids = position_ids\n",
    "        self.next_position_ids = next_position_ids\n",
    "        self.attention_mask = attention_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'position_ids': torch.tensor(self.position_ids[idx], dtype=torch.long),\n",
    "            'next_position_ids': torch.tensor(self.next_position_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx], dtype=torch.long)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:04:59.380641Z",
     "start_time": "2024-06-29T20:04:59.374746Z"
    }
   },
   "id": "80196e9cb33294f1"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Function to shuffle a percentage of tokens within each sequence\n",
    "def shuffle_with_positional_ids(dataset, shuffle_percentage):\n",
    "    shuffled_input_ids_list = []\n",
    "    shuffled_pos_ids_list = []\n",
    "    next_pos_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    for example in dataset:\n",
    "        input_ids = example['input_ids']\n",
    "        attention_mask = example['attention_mask']\n",
    "\n",
    "        # Calculate the number of tokens to shuffle\n",
    "        seq_length = len(input_ids)\n",
    "        num_shuffled_tokens = int(seq_length * shuffle_percentage)\n",
    "\n",
    "        # Get indices to shuffle\n",
    "        indices = list(range(seq_length))\n",
    "        indices_to_shuffle = np.random.choice(indices, num_shuffled_tokens, replace=False)\n",
    "\n",
    "        # Create a permutation for the selected indices\n",
    "        permutation = np.random.permutation(num_shuffled_tokens)\n",
    "\n",
    "        # Create shuffled input_ids, pos_ids, and attention_mask\n",
    "        shuffled_input_ids = input_ids.copy()\n",
    "        pos_ids = list(range(seq_length))\n",
    "        shuffled_pos_ids = pos_ids.copy()\n",
    "        shuffled_attention_mask = attention_mask.copy()\n",
    "\n",
    "        for i, idx in enumerate(indices_to_shuffle):\n",
    "            shuffled_input_ids[idx] = input_ids[indices_to_shuffle[permutation[i]]]\n",
    "            shuffled_pos_ids[idx] = pos_ids[indices_to_shuffle[permutation[i]]]\n",
    "            shuffled_attention_mask[idx] = attention_mask[indices_to_shuffle[permutation[i]]]\n",
    "\n",
    "        # Create the next shuffled pos ids\n",
    "        next_pos_ids = shuffled_pos_ids[1:] + [shuffled_pos_ids[0]]\n",
    "\n",
    "        # Append to lists\n",
    "        shuffled_input_ids_list.append(shuffled_input_ids)\n",
    "        shuffled_pos_ids_list.append(shuffled_pos_ids)\n",
    "        next_pos_ids_list.append(next_pos_ids)\n",
    "        attention_mask_list.append(shuffled_attention_mask)\n",
    "\n",
    "    return ShuffledDataset(\n",
    "        shuffled_input_ids_list,\n",
    "        shuffled_pos_ids_list,\n",
    "        next_pos_ids_list,\n",
    "        attention_mask_list\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:04:59.381251Z",
     "start_time": "2024-06-29T20:04:59.379904Z"
    }
   },
   "id": "ec54e37f1a5b82a0"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Shuffle Percentage=0.0\n",
      "Epoch 1, Batch 0, Loss: 1.4676845073699951\n",
      "Epoch 1, Batch 1, Loss: 20.451215744018555\n",
      "Epoch 1, Batch 2, Loss: 11.188095092773438\n",
      "Epoch 1, Batch 3, Loss: 4.988286018371582\n",
      "Epoch 1, Batch 4, Loss: 5.656720161437988\n",
      "Epoch 1, Batch 5, Loss: 2.509121894836426\n",
      "Epoch 1, Batch 6, Loss: 5.409886837005615\n",
      "Epoch 1, Batch 7, Loss: 4.307000637054443\n",
      "Epoch 1, Batch 8, Loss: 2.30422043800354\n",
      "Epoch 1, Batch 9, Loss: 1.158675193786621\n",
      "Epoch 1, Batch 10, Loss: 3.6322109699249268\n",
      "Epoch 1, Batch 11, Loss: 6.366108417510986\n",
      "Epoch 1, Batch 12, Loss: 3.4161782264709473\n",
      "Epoch 1, Batch 13, Loss: 4.814005374908447\n",
      "Epoch 1, Batch 14, Loss: 7.37620210647583\n",
      "Epoch 1, Batch 15, Loss: 3.746324062347412\n",
      "Epoch 1, Batch 16, Loss: 2.1351242065429688\n",
      "Epoch 1, Batch 17, Loss: 5.646624565124512\n",
      "Epoch 1, Batch 18, Loss: 2.111929416656494\n",
      "Epoch 1, Batch 19, Loss: 1.6194090843200684\n",
      "Epoch 1, Batch 20, Loss: 1.8807986974716187\n",
      "Epoch 1, Batch 21, Loss: 5.878927707672119\n",
      "Epoch 1, Batch 22, Loss: 1.6738231182098389\n",
      "Epoch 1, Batch 23, Loss: 1.44022536277771\n",
      "Epoch 1, Batch 24, Loss: 0.7661375403404236\n",
      "Epoch 1, Batch 25, Loss: 2.9940481185913086\n",
      "Epoch 1, Batch 26, Loss: 1.7144005298614502\n",
      "Epoch 1, Batch 27, Loss: 3.9522321224212646\n",
      "Epoch 1, Batch 28, Loss: 0.1127653419971466\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[40], line 49\u001B[0m\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining completed\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     48\u001B[0m adaptive_shuffle \u001B[38;5;241m=\u001B[39m AdaptiveShuffle()\n\u001B[0;32m---> 49\u001B[0m x, y \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madaptive_shuffle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[40], line 26\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, tokenizer, adaptive_shuffle, train_dataset, eval_dataset, num_epochs, batch_size)\u001B[0m\n\u001B[1;32m     24\u001B[0m labels \u001B[38;5;241m=\u001B[39m input_ids\u001B[38;5;241m.\u001B[39mclone()\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnext_position_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnext_position_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m logits \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlogits\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# Compute loss\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/IdeaProjects/Sigma-GPT/src/transformers/models/gpt2/modeling_gpt2.py:1745\u001B[0m, in \u001B[0;36mCustomGPT2LMHeadModel.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, next_position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1727\u001B[0m transformer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer(\n\u001B[1;32m   1728\u001B[0m     input_ids,\n\u001B[1;32m   1729\u001B[0m     past_key_values\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1741\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m   1742\u001B[0m )\n\u001B[1;32m   1744\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m transformer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m-> 1745\u001B[0m lm_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlm_head\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1747\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def train_model(model, tokenizer, adaptive_shuffle, train_dataset, eval_dataset, num_epochs=10, batch_size=4):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        shuffle_percentage = adaptive_shuffle.get_current_shuffle_percentage()\n",
    "        print(f\"Epoch {epoch + 1}: Shuffle Percentage={shuffle_percentage}\")\n",
    "\n",
    "        # Shuffle the sequences based on the current shuffle percentage\n",
    "        shuffled_train_dataset = shuffle_with_positional_ids(train_dataset, shuffle_percentage)\n",
    "\n",
    "        train_loader = DataLoader(shuffled_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            # Get input and target sequences\n",
    "            input_ids = batch['input_ids'].to(model.device)\n",
    "            position_ids = batch['position_ids'].to(model.device)\n",
    "            next_position_ids = batch['next_position_ids'].to(model.device)\n",
    "            attention_mask = batch['attention_mask'].to(model.device)\n",
    "            labels = input_ids.clone()\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, position_ids=position_ids, next_position_ids=next_position_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            # Compute loss\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = input_ids[..., 1:].contiguous()\n",
    "            loss = loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch_idx % (1 * 1) == 0:\n",
    "                print(f\"Epoch {epoch + 1}, Batch {batch_idx}, Loss: {loss.item()}\")\n",
    "\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        adaptive_shuffle.adjust_shuffle_percentage(average_loss)\n",
    "        print(f\"Epoch {epoch + 1}: Average Loss={average_loss}\")\n",
    "\n",
    "        # Optional: Evaluate on the validation set here\n",
    "\n",
    "    print(\"Training completed\")\n",
    "    \n",
    "adaptive_shuffle = AdaptiveShuffle()\n",
    "x, y = train_model(model, tokenizer, adaptive_shuffle, train_dataset, eval_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:11:52.914053Z",
     "start_time": "2024-06-29T20:10:58.267971Z"
    }
   },
   "id": "a4e123f54a44965"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Shuffle the sequences based on the current shuffle percentage\n",
    "shuffled_train_dataset = shuffle_with_positional_ids(train_dataset, 0)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(shuffled_train_dataset, batch_size=4, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:09:36.828426Z",
     "start_time": "2024-06-29T20:09:31.228492Z"
    }
   },
   "id": "93a27b713146ebec"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(train_loader):\n",
    "    x = batch\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:09:36.833387Z",
     "start_time": "2024-06-29T20:09:36.829319Z"
    }
   },
   "id": "d26fb8f0ee9c6c68"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[ 1550, 27512,   705,  ..., 50256, 50256, 50256],\n         [50256, 50256, 50256,  ..., 50256, 50256, 50256],\n         [  796,   796,   609,  ..., 50256, 50256, 50256],\n         [  796,   796, 39978,  ..., 50256, 50256, 50256]]),\n 'position_ids': tensor([[  0,   1,   2,  ..., 253, 254, 255],\n         [  0,   1,   2,  ..., 253, 254, 255],\n         [  0,   1,   2,  ..., 253, 254, 255],\n         [  0,   1,   2,  ..., 253, 254, 255]]),\n 'next_position_ids': tensor([[  1,   2,   3,  ..., 254, 255,   0],\n         [  1,   2,   3,  ..., 254, 255,   0],\n         [  1,   2,   3,  ..., 254, 255,   0],\n         [  1,   2,   3,  ..., 254, 255,   0]]),\n 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0]])}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:09:36.837649Z",
     "start_time": "2024-06-29T20:09:36.833969Z"
    }
   },
   "id": "85afdf7eb8960c2d"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256]),\n 'position_ids': tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n         252, 253, 254, 255]),\n 'next_position_ids': tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n          29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n          57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n          71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n          99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n         113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n         127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n         141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n         155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n         169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n         183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n         197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n         225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n         239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n         253, 254, 255,   0]),\n 'attention_mask': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_train_dataset[12]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T20:10:34.454663Z",
     "start_time": "2024-06-29T20:10:34.446163Z"
    }
   },
   "id": "51d608bd1b64d73d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f3b345b4707cf6c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
